<div align="center">   
  
# V2X-Seq: A Large-Scale Sequential Dataset for  Vehicle-Infrastructure Cooperative Perception and Forecasting, CVPR2023
</div> 

  ![](./resources/tracking-demo.gif "")
  ![](./resources/forecasting-demo.gif "")


## Introduction 
V2X-Seq is the first large-scale, real-world, and sequential V2X dataset, which includes data frames, trajectories, vector maps, and traffic lights captured from natural scenery. V2X-Seq comprises two parts: the sequential perception dataset, which includes more than 15,000 frames captured from 95 scenarios, and the trajectory forecasting dataset, which contains about 80,000 infrastructure-view scenarios, 80,000 vehicle-view scenarios, and 50,000 cooperative-view scenarios captured from 28 intersections' areas, covering 672 hours of data.

## News
* [2023.03] ðŸ”¥ Our new dataset "V2X-Seq: A Large-Scale Sequential Dataset for Vehicle-Infrastructure Cooperative Perception and Forecasting" has been accepted by CVPR2023. Congratulations! We will release the dataset sooner. 

## Dataset 

V2X-Seq is one of our [DAIR-V2X dataset series](https://thudair.baai.ac.cn/index).  Download links are as follows:

- Sequential Perception Dataset (SPD): [Coming soon].
- Trajectory Forecasting Dataset (TFD): [Coming soon].
- Example Dataset: [Coming soon].


## Benchmarks
Coming soon.

## Citation
Please consider citing our paper if the project helps your research with the following BibTex:
```bibtex
@inproceedings{v2x-seq,
  title={V2X-Seq: A large-scale sequential dataset for vehicle-infrastructure cooperative perception and forecasting},
  author={Yu, Haibao and Yang, Wenxian and Ruan, Hongzhi and Yang, Zhenwei and Tang, Yingjuan and Gao, Xu and Hao, Xin and Shi, Yifeng and Pan, Yifeng and Sun, Ning and Song, Juan and Yuan, Jirui and Luo, Ping and Nie, Zaiqing},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  year={2023},
}
```
```bibtex
@inproceedings{dair-v2x,
  title={Dair-v2x: A large-scale dataset for vehicle-infrastructure cooperative 3d object detection},
  author={Yu, Haibao and Luo, Yizhen and Shu, Mao and Huo, Yiyi and Yang, Zebang and Shi, Yifeng and Guo, Zhenglong and Li, Hanyu and Hu, Xing and Yuan, Jirui and Nie, Zaiqing},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={21361--21370},
  year={2022}
}
```

## Related Resources

[![Awesome](https://awesome.re/badge.svg)](https://awesome.re)

- [DAIR-V2X](https://github.com/AIR-THU/DAIR-V2X) (:rocket:Ours!)
- [FFNET](https://github.com/haibao-yu/FFNet-VIC3D) (:rocket:Ours!)